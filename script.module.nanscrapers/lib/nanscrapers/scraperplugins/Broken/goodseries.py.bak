import re
import requests,base64
import xbmc
from ..scraper import Scraper
from ..common import clean_title,clean_search,filter_host
User_Agent = 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 Safari/537.36'

class goodseries(Scraper):
    domains = ['https://goodseries.ga']
    name = "GoodSeries"
    sources = []

    def __init__(self):
        self.base_link = 'https://goodseries.ga/'
        self.search = self.base_link+'instant-search.php?q='
                          
    def scrape_episode(self, title, show_year, year, season, episode, imdb, tvdb, debrid = False):
        try:
            search = clean_search(title.lower()).replace(' ','%20')
            start_url = self.search + search
            #print 'check start '+start_url
            headers={'User-Agent':User_Agent}
            html = requests.get(start_url,headers=headers, timeout=3).content
            match = re.compile("href='(.+?)'>(.+?)<",re.DOTALL).findall(html)
            for url,name in match:
                url = self.base_link+url
                if clean_title(title).lower() == clean_title(name).lower():

                    html2 = requests.get(url).content
                    match2 = re.compile("class='cmll-host'>(.+?)</td>.+?href='(.+?)'",re.DOTALL).findall(html2)
                    
                    sea_epi ='Season %s Episode %s'%(season,episode)
                    
                    for ep_name,url2 in match2:
                        #print 'got %s %s' %(ep_name,url2)
                        if sea_epi in ep_name:
                            url2 = self.base_link + url2
                            #print 'gw-chkep '+ url2
                            self.get_source(url2)
            return self.sources
        except Exception as e:
            print repr(e)
            pass
            return []                           

    def scrape_movie(self, title, year, imdb, debrid = False):
        try:
            search = clean_search(title.lower()).replace(' ','%20')
            start_url = self.search + search
            #print 'check start '+start_url
            headers={'User-Agent':User_Agent}
            html = requests.get(start_url,headers=headers, timeout=3).content
            match = re.compile("href='(.+?)'>(.+?)<",re.DOTALL).findall(html)
            for url2,name in match:
                url2 = self.base_link+url2
                if clean_title(title).lower() == clean_title(name).lower():
                    if year in name:
                        #print 'gw-chkep '+ url2
                        self.get_source(url2)
            return self.sources
        except:
            pass
            return[]

    def get_source(self,url2):
        try:
            html = requests.get(url2).content
            links = re.compile("href='watch/(.+?)'",re.DOTALL).findall(html)
            for link in links:
                #print '64 > '+link
                url = base64.b64decode(link)
                host = url.split('//')[1].replace('www.','')
                host = host.split('/')[0].lower()
                if not filter_host(host):
                    continue
                #print 'final url '+url
                self.sources.append({'source': host, 'quality': 'DVD', 'scraper': self.name, 'url': url,'direct': False})
        except:
            pass

